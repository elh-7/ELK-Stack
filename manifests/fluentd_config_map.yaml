# ================================================================
# FLUENTD CONFIGMAP
# Configuración principal de Fluentd para envío de logs a Elasticsearch
# ================================================================

---                                # Separador opcional para indicar inicio de un nuevo documento YAML
apiVersion: v1                     # Versión de la API de Kubernetes para ConfigMaps
kind: ConfigMap                    # Tipo de recurso: ConfigMap (almacena datos de configuración no confidenciales)

metadata:
  name: fluentd-config             # Nombre del ConfigMap (referenciado por el Deployment o DaemonSet de Fluentd)
  namespace: logging               # Namespace donde se despliega el ConfigMap

data:                              # Contiene los datos clave-valor que se almacenan dentro del ConfigMap
  fluent.conf: |                   # Archivo de configuración principal de Fluentd, escrito en formato heredado de td-agent

    # ============================================================
    # FUENTE DE DATOS (INPUT)
    # Lee los logs de los contenedores de Kubernetes
    # ============================================================
    <source>
      @type tail                   # Plugin de entrada: 'tail' lee archivos de log línea por línea (como tail -f)
      path /var/log/containers/*.log       # Ruta donde Kubernetes guarda los logs de los contenedores
      pos_file /var/log/fluentd-containers.log.pos  # Archivo donde Fluentd guarda su posición de lectura (evita leer logs duplicados)
      tag kubernetes.*             # Etiqueta aplicada a todos los logs capturados desde contenedores
      format multiline              # Indica que algunos logs pueden tener múltiples líneas (por ejemplo, trazas de errores)
      format_firstline /\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}/
                                   # Expresión regular que detecta la primera línea de un nuevo evento de log (por su timestamp)
      format1 /^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[FP]) (?<message>.*)$/
                                   # Patrón para extraer campos del log: hora, flujo (stdout/stderr), tipo y mensaje
      time_format %Y-%m-%dT%H:%M:%S.%N%:z
                                   # Formato de tiempo usado para interpretar el timestamp de los logs
    </source>

    # ============================================================
    # DESTINO DE DATOS (OUTPUT)
    # Envía los logs procesados a Elasticsearch
    # ============================================================
    <match kubernetes.**>          # Coincide con todos los logs etiquetados como 'kubernetes.*'
      @type elasticsearch          # Plugin de salida: envía los datos al servicio de Elasticsearch
      host elasticsearch           # Nombre del host o servicio (resuelto vía DNS en Kubernetes)
      port 9200                    # Puerto del API REST de Elasticsearch
      scheme https                 # Usa protocolo HTTPS para comunicación cifrada
      ssl_verify false             # Desactiva la verificación SSL (útil para certificados autofirmados)
      user elastic                 # Usuario con permisos para escribir en Elasticsearch
      password TuPasswordSeguro    # Contraseña del usuario 'elastic' (debe coincidir con la configurada en el StatefulSet)
      index_name fluentd           # Nombre del índice donde se almacenarán los logs
      logstash_format true         # Activa el formato compatible con Logstash (crea índices rotativos por fecha, ej. fluentd-2025.11.06)
      include_tag_key true         # Incluye la clave de etiqueta en el documento almacenado
      tag_key @log_name            # Define el nombre de campo para la etiqueta dentro de los documentos
    </match>

# ---------------------------------------------------------------
# RESUMEN FUNCIONAL:
# - Lee los logs desde /var/log/containers/*.log en cada nodo.
# - Aplica un formato multiline para eventos largos (como stacktraces).
# - Envía los logs al servicio Elasticsearch en el namespace "logging".
# - Usa conexión HTTPS (aunque sin validación estricta del certificado).
# - Autenticación con usuario "elastic" y contraseña definida.
# - Los índices se crean automáticamente con formato de fecha (logstash_format).
# ---------------------------------------------------------------
