# ğŸ§© Elasticsearch Components

![Elasticsearch Components](<img width="1025" height="577" alt="image" src="https://github.com/user-attachments/assets/2ba47f8c-ef7b-4d7e-bd86-5ac538c43014" />
)

> Diagrama explicativo de la arquitectura interna de **Elasticsearch**, mostrando la relaciÃ³n entre *cluster*, *nodos*, *shards*, *rÃ©plicas* e *Ã­ndices*.

---

## ğŸ“˜ DescripciÃ³n general

**Elasticsearch** es un motor de bÃºsqueda y anÃ¡lisis distribuido basado en **Apache Lucene**.  
Su diseÃ±o permite almacenar, buscar y analizar grandes volÃºmenes de datos casi en tiempo real.

El diagrama anterior ilustra cÃ³mo los datos son organizados y distribuidos dentro del clÃºster.

---

## ğŸ—ï¸ Estructura del ClÃºster

### ğŸ”¹ Cluster
- Es el conjunto completo de nodos de Elasticsearch que trabajan de forma coordinada.
- Cada clÃºster tiene un **nombre Ãºnico** (por ejemplo, `efk-cluster`).
- Dentro del clÃºster, uno de los nodos es elegido como **nodo maestro**, encargado de:
  - Administrar la configuraciÃ³n global.
  - Supervisar el estado de los nodos.
  - Coordinar la creaciÃ³n y asignaciÃ³n de *shards*.

### ğŸ”¹ Nodes
- Un **nodo** es una instancia individual de Elasticsearch en ejecuciÃ³n (por ejemplo, un Pod en Kubernetes).
- Cada nodo almacena una parte de los datos y participa en el procesamiento de consultas.
- Existen diferentes tipos de nodos:
  - ğŸ§­ **Master Node:** coordina el clÃºster.
  - ğŸ“¦ **Data Node:** almacena datos y ejecuta operaciones de bÃºsqueda y agregaciÃ³n.
  - ğŸ” **Ingest Node:** realiza transformaciones de datos antes del indexado.
  - ğŸ§± **Coordinating Node:** distribuye las consultas entrantes entre los nodos de datos.

---

## ğŸ“‚ OrganizaciÃ³n de los datos

### ğŸ”¸ Index
- Un **Ã­ndice** es una colecciÃ³n lÃ³gica de documentos relacionados.
- Equivale a una â€œbase de datosâ€ en el mundo relacional.
- Cada Ã­ndice estÃ¡ dividido en mÃºltiples **shards** (fragmentos).

### ğŸ”¸ Shards
- Un **shard** es una unidad fÃ­sica de almacenamiento y procesamiento dentro del Ã­ndice.
- Permite dividir los datos de un Ã­ndice en fragmentos mÃ¡s pequeÃ±os para distribuir la carga entre nodos.
- Existen dos tipos:
  - **Primary Shard:** almacena los datos originales.
  - **Replica Shard:** copia exacta de un *primary shard* que proporciona tolerancia a fallos y balanceo de lectura.

### ğŸ”¸ Replicas
- Las **rÃ©plicas** se distribuyen en diferentes nodos para garantizar la alta disponibilidad.
- Si un nodo falla, otro nodo con la rÃ©plica puede continuar sirviendo consultas.

---

## ğŸ“œ Documentos y Campos

- Un **documento** representa la unidad mÃ­nima de informaciÃ³n que puede ser indexada.
- Cada documento contiene mÃºltiples **campos** (equivalentes a columnas en una base de datos relacional).
- Los documentos se almacenan en Ã­ndices, y los Ã­ndices se dividen en shards, que son manejados por los nodos del clÃºster.

---

## âš™ï¸ Flujo de datos resumido

1. **El clÃºster** coordina todos los nodos.
2. **Los nodos** almacenan shards del Ã­ndice y procesan consultas.
3. **Los shards** dividen los Ã­ndices para distribuir la carga.
4. **Las rÃ©plicas** aseguran disponibilidad y redundancia.
5. **Los documentos** son almacenados dentro de los shards, y sus **campos** permiten bÃºsquedas rÃ¡pidas y precisas.

---

## ğŸš€ Beneficios de esta arquitectura

- **Escalabilidad horizontal:** se pueden aÃ±adir mÃ¡s nodos fÃ¡cilmente.
- **Alta disponibilidad:** gracias a las rÃ©plicas distribuidas.
- **Rendimiento optimizado:** consultas y escrituras paralelas.
- **RecuperaciÃ³n ante fallos:** los datos se mantienen disponibles incluso si un nodo cae.

---

# Arquitectura y Flujo de Datos en **Fluentd**

![Fluentd Data Flow](<img width="911" height="291" alt="image" src="https://github.com/user-attachments/assets/af4dca37-1fe3-4e0a-ac61-573c4d74d5f8" />
)

## ğŸ“˜ IntroducciÃ³n

**Fluentd** es un recolector de datos de cÃ³digo abierto que unifica la recopilaciÃ³n y el consumo de logs.  
Permite tomar datos desde mÃºltiples fuentes, transformarlos, y enviarlos hacia distintos destinos como bases de datos, sistemas de almacenamiento o herramientas de anÃ¡lisis (por ejemplo, Elasticsearch o Kibana).

Su arquitectura se basa en un flujo flexible compuesto por tres etapas principales:

> **Input â†’ Filter â†’ Output**

---

## ğŸ§© Componentes Principales

### 1. **Input (Entrada)**

El bloque **Input** representa la fase inicial del procesamiento.  
AquÃ­ Fluentd **recibe datos desde diversas fuentes**, como:

- Archivos de log del sistema (`/var/log/...`)
- Aplicaciones que generan eventos o mÃ©tricas
- Bases de datos o sockets TCP/UDP
- Herramientas de monitoreo o pipelines de datos

Cada fuente se define mediante un **plugin de entrada** (`in_*`), como por ejemplo:
```bash
<source>
  @type tail
  path /var/log/syslog
  tag system.logs
</source>
````

ğŸ”¹ *FunciÃ³n:* Capturar los datos sin alterar su contenido, asignarles una etiqueta (`tag`) y enviarlos al siguiente paso del flujo.

---

### 2. **Filter (Filtro)**

El bloque **Filter** se encarga de **transformar, estructurar o enriquecer los datos** antes de enviarlos al destino.

Algunas tareas comunes incluyen:

* Parseo de formato (JSON, CSV, texto plano, etc.)
* ExtracciÃ³n de campos especÃ­ficos
* AnonimizaciÃ³n de informaciÃ³n sensible
* Enriquecimiento con metadatos adicionales (por ejemplo, nombre del host o timestamp formateado)

Ejemplo:

```bash
<filter system.logs>
  @type record_transformer
  <record>
    hostname ${hostname}
  </record>
</filter>
```

ğŸ”¹ *FunciÃ³n:* Asegurar que los datos tengan una estructura coherente y lista para su anÃ¡lisis posterior.

---

### 3. **Output (Salida)**

El bloque **Output** define **a dÃ³nde se envÃ­an los datos procesados**.
Fluentd soporta una gran variedad de destinos mediante plugins (`out_*`), entre ellos:

* **Elasticsearch** â†’ para bÃºsqueda y visualizaciÃ³n con Kibana
* **S3 / GCS** â†’ para almacenamiento a largo plazo
* **Prometheus / Loki** â†’ para monitoreo
* **stdout / archivo** â†’ para depuraciÃ³n o testing

Ejemplo:

```bash
<match system.logs>
  @type elasticsearch
  host elasticsearch.logging.svc
  port 9200
  index_name fluentd-logs
</match>
```

ğŸ”¹ *FunciÃ³n:* Enviar los datos transformados hacia su destino final para almacenamiento o anÃ¡lisis.

---

## ğŸ§  Flujo de Datos Resumido

1. **Data** â€” Se genera en aplicaciones, servidores o contenedores.
2. **Input** â€” Fluentd recibe los logs mediante un plugin de entrada.
3. **Filter** â€” Los datos se transforman o enriquecen segÃºn las reglas configuradas.
4. **Output** â€” Se entregan al sistema de destino (por ejemplo, Elasticsearch).
5. **Destination** â€” Los datos son analizados o almacenados de forma permanente.

---

## âš™ï¸ Ventajas de Fluentd

* Modularidad mediante **plugins** (mÃ¡s de 500 disponibles).
* Manejo eficiente de datos estructurados y no estructurados.
* IntegraciÃ³n directa con el **ELK/EFK Stack**.
* Alta tolerancia a fallos y bufferizaciÃ³n configurable.
* Soporte para enrutar datos segÃºn etiquetas o patrones.

---

## ğŸ“š ConclusiÃ³n

Fluentd actÃºa como un **intermediario inteligente** entre las fuentes de datos y sus destinos finales, asegurando un transporte confiable y flexible de la informaciÃ³n.
Gracias a su arquitectura basada en *Input â†’ Filter â†’ Output*, permite construir pipelines robustos de observabilidad dentro de entornos **Kubernetes**, **Docker** o sistemas distribuidos.

---

# VisualizaciÃ³n y AnÃ¡lisis de Datos con **Kibana**

![Kibana Data Visualization](<img width="2814" height="1154" alt="image" src="https://github.com/user-attachments/assets/f4b790f7-3873-42a2-baa8-2d87bf97d3f0" />
)

## ğŸ“˜ IntroducciÃ³n

**Kibana** es la interfaz de visualizaciÃ³n y anÃ¡lisis de datos del ecosistema **Elastic Stack (ELK)**.  
Permite explorar, visualizar y comprender grandes volÃºmenes de informaciÃ³n almacenados en **Elasticsearch**, mediante grÃ¡ficos interactivos, dashboards y herramientas de monitoreo en tiempo real.

Kibana es la capa final del flujo **Input â†’ Storage â†’ Visualization**, funcionando como el **punto de acceso visual** a los datos procesados por **Fluentd** o **Logstash** y almacenados por **Elasticsearch**.

---

## ğŸ§© Componentes Principales

### 1. **Data Source (Fuente de datos)**

Los datos provienen del motor de bÃºsqueda **Elasticsearch**, que indexa documentos y estructuras de informaciÃ³n previamente recolectadas por herramientas como **Fluentd** o **Logstash**.

Cada Ã­ndice en Elasticsearch representa un conjunto de datos que Kibana puede consultar y visualizar.  
El vÃ­nculo entre ambos se establece mediante un **Index Pattern**, que define quÃ© Ã­ndices se usarÃ¡n en los dashboards.

Ejemplo:
```bash
Index Pattern: logs-* 
````

ğŸ”¹ *FunciÃ³n:* Proveer la informaciÃ³n ya indexada y estructurada que Kibana transformarÃ¡ en grÃ¡ficos, tablas y reportes.

---

### 2. **Discover (Explorar Datos)**

El mÃ³dulo **Discover** permite **examinar datos sin procesar** directamente desde Elasticsearch.
A travÃ©s de filtros, campos y bÃºsquedas con la sintaxis de consulta **Lucene** o **KQL (Kibana Query Language)**, el usuario puede:

* Navegar registros cronolÃ³gicamente.
* Ver los campos individuales de cada documento.
* Exportar consultas o resultados para anÃ¡lisis adicionales.

Ejemplo de bÃºsqueda en KQL:

```bash
status_code >= 400 AND response_time > 1000
```

ğŸ”¹ *FunciÃ³n:* Brindar una vista granular de los registros para entender el contexto antes de construir visualizaciones.

---

### 3. **Visualize (Visualizaciones)**

El mÃ³dulo **Visualize** permite **crear representaciones grÃ¡ficas interactivas** basadas en los datos indexados.
Soporta mÃºltiples tipos de grÃ¡ficos:

* Barras, lÃ­neas y Ã¡reas
* Mapas de calor y geogrÃ¡ficos
* Tabelas dinÃ¡micas y mÃ©tricas numÃ©ricas
* Series temporales (TSVB)

Cada visualizaciÃ³n puede alimentarse de una o varias consultas de Elasticsearch y ser reutilizada en paneles.

ğŸ”¹ *FunciÃ³n:* Convertir los datos en informaciÃ³n visual fÃ¡cilmente interpretable.

---

### 4. **Dashboard (Paneles de control)**

Los **Dashboards** agrupan varias visualizaciones para **proporcionar una vista consolidada del sistema**.
Pueden configurarse para mostrar mÃ©tricas de infraestructura, rendimiento de aplicaciones o seguridad, todo en tiempo real.

Los paneles pueden incluir:

* Filtros dinÃ¡micos (por tiempo, host, servicio, etc.)
* Vistas en tiempo real actualizadas automÃ¡ticamente
* Alertas visuales ante anomalÃ­as o errores

Ejemplo de uso:

> Un dashboard de monitoreo de Kubernetes mostrando el consumo de CPU, logs de contenedores y errores HTTP 500.

ğŸ”¹ *FunciÃ³n:* Facilitar el monitoreo integral y la toma de decisiones basada en datos.

---

### 5. **Alerts & Reports (Alertas y Reportes)**

Kibana permite **crear alertas automÃ¡ticas** que se activan segÃºn condiciones definidas sobre los datos.
Estas alertas pueden enviar notificaciones por correo, Slack u otros canales cuando se detecten eventos crÃ­ticos.

AdemÃ¡s, se pueden generar **reportes PDF o CSV** programados desde dashboards o visualizaciones.

Ejemplo:

```bash
Trigger: response_time > 2000ms
Action: Send Slack alert to #devops
```

ğŸ”¹ *FunciÃ³n:* Automatizar la observaciÃ³n y comunicaciÃ³n de eventos relevantes dentro de la infraestructura.

---

## ğŸ”„ Flujo de Datos en el ELK Stack

1. **Fluentd / Logstash** recolectan y procesan los logs.
2. **Elasticsearch** indexa y almacena los datos.
3. **Kibana** los consulta, filtra y visualiza en paneles interactivos.
4. Los usuarios exploran, analizan y crean alertas para observabilidad continua.

---

## âš™ï¸ Ventajas de Kibana

* VisualizaciÃ³n **en tiempo real** de datos de Elasticsearch.
* IntegraciÃ³n nativa con los demÃ¡s componentes del **Elastic Stack**.
* Potente lenguaje de consultas (**KQL / Lucene**).
* Amplio catÃ¡logo de **grÃ¡ficos y visualizaciones personalizables**.
* Soporte para **alertas, reportes y machine learning**.
* Compatible con **roles, usuarios y seguridad granular** (X-Pack).

---

## ğŸ“š ConclusiÃ³n

**Kibana** es la capa de observabilidad visual dentro del **ELK/EFK Stack**.
Permite convertir datos complejos en conocimiento Ãºtil a travÃ©s de dashboards interactivos, detecciÃ³n de anomalÃ­as y anÃ¡lisis temporal.

En entornos modernos â€”como **Kubernetes**, **microservicios** o **infraestructura cloud**â€”, Kibana se convierte en una herramienta esencial para la **analÃ­tica, monitoreo y diagnÃ³stico operacional**.

---
Â© 2025 â€” Elaborado para documentaciÃ³n tÃ©cnica de despliegue **EFK (Elasticsearch, Fluentd, Kibana)** en entornos Kubernetes por Axel Bautista y Emanuel LÃ³pez - UNAM FI 
